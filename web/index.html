<!DOCTYPE html>
<html>
<head>
  <base href="$FLUTTER_BASE_HREF">

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <meta name="description" content="A Chat and Task Combo!">
  <meta name="theme-color" content="#0175C2">

  <!-- iOS meta tags & icons -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-title" content="AccuChat">
  <link rel="apple-touch-icon" sizes="192x192" href="icons/Icon-192.png">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="favicon.png"/>

  <title>AccuChat</title>
  <link rel="manifest" href="manifest.json">

  <!-- External Libraries -->
  <link href="https://unpkg.com/cropperjs/dist/cropper.min.css" rel="stylesheet"/>
  <script src="https://unpkg.com/cropperjs/dist/cropper.min.js"></script>

  <!-- Firebase SDK -->
  <script src="https://www.gstatic.com/firebasejs/10.12.2/firebase-app-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/10.12.2/firebase-messaging-compat.js"></script>
</head>

<body>
<script src="flutter_bootstrap.js" async></script>

<script>
  // Remove loading element once Flutter is ready
  window.addEventListener('flutter-first-frame', function () {
    document.getElementById('loading')?.remove();
  });

  // ✅ Register Firebase Messaging Service Worker (supports root + subpath)
  (function registerFcmServiceWorker() {
    if (!('serviceWorker' in navigator)) return;

    const base = document.querySelector('base')?.getAttribute('href') ?? '/';
    const basePath = base.endsWith('/') ? base : base + '/';
    const swPath = basePath + 'firebase-messaging-sw.js';

    navigator.serviceWorker.register(swPath)
      .then((reg) => console.log('✅ Service Worker registered with scope:', reg.scope))
      .catch((err) => console.error('❌ Service Worker registration failed:', err));
  })();
</script>
<script>
  (function () {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      window.__speech_not_supported__ = true;
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-IN';

    // ---- internal state ----
    let permissionBlocked = false;     // user denied mic
    let lastStartAt = 0;
    const START_COOLDOWN_MS = 1200;    // prevents rapid re-start loops

    function now() { return Date.now(); }

    function safeStart() {
      if (permissionBlocked) return; // don't re-prompt forever
      const t = now();
      if (t - lastStartAt < START_COOLDOWN_MS) return; // cooldown
      lastStartAt = t;

      try {
        recognition.start();
        window.__speech__.isListening = true;
      } catch (e) {
        // start() can throw if called while already started; ignore
      }
    }

    function safeStop() {
      try {
        recognition.stop();
      } catch (e) {}
      window.__speech__.isListening = false;
    }

    window.__speech__ = {
      isListening: false,
      // expose permission state to Flutter
      blocked: function () { return permissionBlocked; },
      // only call start from an explicit user action in Flutter if possible
      start: function () { safeStart(); },
      stop: function () { safeStop(); },
      setLang: function (lang) { recognition.lang = lang || 'en-IN'; },
      // call this ONLY when the user explicitly taps "Try again"
      resetPermissionBlock: function () { permissionBlocked = false; }
    };

    recognition.onresult = function (event) {
      let interim = '';
      let finalText = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) finalText += transcript;
        else interim += transcript;
      }

      window.dispatchEvent(new CustomEvent('speech-result', {
        detail: { interim: interim, final: finalText }
      }));
    };

    recognition.onerror = function (e) {
      const err = (e && (e.error || e.message)) ? (e.error || e.message) : 'speech_error';

      // IMPORTANT: these mean the user blocked mic permission
      if (err === 'not-allowed' || err === 'permission-denied' || err === 'service-not-allowed') {
        permissionBlocked = true;
        safeStop();
      }

      window.dispatchEvent(new CustomEvent('speech-error', { detail: err }));
    };

    recognition.onend = function () {
      window.__speech__.isListening = false;
      window.dispatchEvent(new CustomEvent('speech-end'));

      // Do NOT auto-restart here if permission is blocked.
      // If your Flutter code currently restarts on 'speech-end', guard it using __speech__.blocked().
    };
  })();
</script>

<script>
  window.addEventListener("paste", async (event) => {
    if (!event.clipboardData) return;

    for (const item of event.clipboardData.items) {
      if (item.type.startsWith("image/")) {
        const blob = item.getAsFile();
        const arrayBuffer = await blob.arrayBuffer();
        const bytes = new Uint8Array(arrayBuffer);

        window.flutterImagePasteHandler?.({
          name: blob.name || "pasted-image.png",
          type: blob.type,
          bytes: Array.from(bytes)
        });

        event.preventDefault();
      }
    }
  });
</script>

<script src="flutter_bootstrap.js" async></script>

</body>
</html>
